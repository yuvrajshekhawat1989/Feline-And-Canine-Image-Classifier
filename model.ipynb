{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from shutil import move,rmtree\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a directory structure for dataset to use keras API\n",
    "dataset_home = 'dataset_dogs_vs_cats/'\n",
    "subdirs = ['train/','test/']\n",
    "labeldirs = ['dogs/','cats/']\n",
    "for subdir in subdirs:\n",
    "    for labeldir in labeldirs:\n",
    "        newdir = dataset_home+subdir+labeldir\n",
    "        os.makedirs(newdir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the corrrupt Images from dataset\n",
    "dataset_dirs = ['PetImages/Dog/','PetImages/Cat/']  # Replace with the path to your dataset directory\n",
    "\n",
    "corrupted_images = []  # List to store the paths of corrupted images\n",
    "\n",
    "# Iterate through the dataset directory\n",
    "for dataset_dir in dataset_dirs:\n",
    "    for root, dirs, files in os.walk(dataset_dir):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                # Attempt to open the image\n",
    "                Image.open(file_path)\n",
    "            except (IOError, OSError):\n",
    "                # Add the file path to the list of corrupted images\n",
    "                corrupted_images.append(file_path)\n",
    "\n",
    "# Print the corrupted images\n",
    "print(\"Corrupted Images:\")\n",
    "for img_path in corrupted_images:\n",
    "    print(img_path)\n",
    "\n",
    "# Delete the corrupted images\n",
    "for img_path in corrupted_images:\n",
    "    os.remove(img_path)\n",
    "\n",
    "print(\"Corrupted images removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the dataset Images to our created directory structure\n",
    "testRatio = 0.2 # The ratio of images that will be included in test dataset\n",
    "np.random.seed(1) #Seeding\n",
    "src_folders = ['PetImages/Dog/','PetImages/Cat/']\n",
    "for folder in src_folders:\n",
    "    for file in os.listdir(folder):\n",
    "        src = folder+file\n",
    "        dst_dir = 'train/'\n",
    "        if np.random.random()<testRatio:\n",
    "            dst_dir = 'test/'\n",
    "        dst = dataset_home+dst_dir\n",
    "        if folder=='PetImages/Cat/':\n",
    "            dst+='cats/'\n",
    "        else:\n",
    "            dst+='dogs/'\n",
    "        dst+=file\n",
    "        move(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same',input_shape=(200,200,3)))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation='relu',kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    # compile model\n",
    "    opt= SGD(learning_rate=0.001,momentum=0.9)\n",
    "    model.compile(opt,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = define_model()\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "train_it = datagen.flow_from_directory(directory='dataset_dogs_vs_cats/train/',\n",
    "                                       class_mode='binary',batch_size=64,target_size=(200,200))\n",
    "test_it = datagen.flow_from_directory(directory='dataset_dogs_vs_cats/test/',\n",
    "                                      class_mode='binary',batch_size=64,target_size=(200,200))\n",
    "# training the model\n",
    "history = model.fit(train_it,steps_per_epoch=len(train_it),\n",
    "                    validation_data=test_it,validation_steps=len(test_it),epochs=20,verbose=0)\n",
    "# evaluate model\n",
    "_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "print('> %.3f' % (acc * 100.0))\n",
    "# plot diagnostic learning curves\n",
    "# plot loss\n",
    "plt.subplot(211)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(history.history['loss'], color='blue', label='train')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "# plot accuracy\n",
    "plt.subplot(212)\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "# save plot to file\n",
    "filename = sys.argv[0].split('/')[-1]\n",
    "plt.savefig(filename + '_plot.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
